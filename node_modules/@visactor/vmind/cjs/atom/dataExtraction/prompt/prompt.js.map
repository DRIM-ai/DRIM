{"version":3,"sources":["../src/atom/dataExtraction/prompt/prompt.ts"],"names":[],"mappings":";;;AACA,4CAAmD;AACnD,iDAAuE;AACvE,iDAAmE;AACnE,2CAA6D;AAC7D,yCAAiD;AAAxC,+GAAA,kBAAkB,OAAA;AAEpB,MAAM,aAAa,GAAG,CAC3B,KAAa,EACb,QAA+B,EAC/B,UAAU,GAAG,KAAK,EAClB,cAAuB,KAAK,EAC5B,EAAE;IACF,IAAI,UAAU,EAAE;QACd,OAAO,IAAA,mBAAa,EAAC,KAAK,CAAC,CAAC,CAAC,CAAC,IAAA,8BAAe,EAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,IAAA,mCAAoB,EAAC,QAAQ,CAAC,CAAC;KAC1F;IACD,MAAM,IAAI,GAAG,IAAA,mBAAa,EAAC,KAAK,CAAC,CAAC,CAAC,CAAC,4BAAgB,CAAC,CAAC,CAAC,yBAAa,CAAC;IACrE,OAAO,IAAI,CAAC,QAAQ,EAAE,WAAW,CAAC,CAAC;AACrC,CAAC,CAAC;AAXW,QAAA,aAAa,iBAWxB;AAEK,MAAM,YAAY,GAAG,CAAC,KAAa,EAAE,QAA+B,EAAE,UAAU,GAAG,KAAK,EAAgB,EAAE;IAC/G,IAAI,UAAU,IAAI,CAAC,IAAA,mBAAa,EAAC,KAAK,CAAC,EAAE;QACvC,OAAO;YACL;gBACE,IAAI,EAAE,MAAM;gBACZ,OAAO,EAAE,kBAAkB;aAC5B;SACF,CAAC;KACH;IACD,OAAO,EAAE,CAAC;AACZ,CAAC,CAAC;AAVW,QAAA,YAAY,gBAUvB","file":"prompt.js","sourcesContent":["import type { LLMMessage } from '../../../types';\nimport { isDoubaoModel } from '../../../utils/llm';\nimport { getCapCutPrompt, getCapCutPromptInGpt } from './capcutPrompt';\nimport { getBasePrompt as doubaoBasePrompt } from './doubaoPrompt';\nimport { getBasePrompt as gptBasePrompt } from './gptPrompt';\nexport { getFieldInfoPrompt } from './gptPrompt';\n\nexport const getBasePrompt = (\n  model: string,\n  language: 'chinese' | 'english',\n  isMultiple = false,\n  showThoughs: boolean = false\n) => {\n  if (isMultiple) {\n    return isDoubaoModel(model) ? getCapCutPrompt(language) : getCapCutPromptInGpt(language);\n  }\n  const func = isDoubaoModel(model) ? doubaoBasePrompt : gptBasePrompt;\n  return func(language, showThoughs);\n};\n\nexport const getUserQuery = (model: string, language: 'chinese' | 'english', isMultiple = false): LLMMessage[] => {\n  if (isMultiple && !isDoubaoModel(model)) {\n    return [\n      {\n        role: 'user',\n        content: 'Extract all data'\n      }\n    ];\n  }\n  return [];\n};\n"]}